# 가상 면접 사례로 배우는 대규모 시스템 설계 기초

### 1장 사용자 수에 따른 규모 확장성

- 단일 서버
    - 사용자 요청 흐름
        1. 사용자는 도메인 이름을 이용해 웹사이트에 접속
            
            DNS에 query해서 IP 주소로 변환하는 과정 필요
            
        2. DNS 조회 결과로 IP 주소 반환
        3. 해당 IP 주소로 HTTP 요청이 전달
        4. 요청을 받은 웹 서버는 HTML 페이지나 JSON 형태의 응답을 반환
    - 실제 요청이 어디로부터 오는지?
        - 웹 애플리케이션 : 비즈니스 로직, 데이터 저장 등을 처리하기 위해서는 서버 구현용 언어(자바, 파이썬 등)를 사용하고, 프레젠테이션용으로는 클라이언트 구현용 언어를(HTML, 자바스크립트 등) 사용
        - 모바일 앱 : 모바일 앱과 웹 서버 간 통신을 위해서는 HTTP 프로토콜을 이용한다. HTTP 프로토콜을 통해서 반환될 응답 데이터의 포맷으로는 보통 JSON(JavaScript Object Notation)이 간결해서 많이 사용된다.
- 데이터베이스
    - 웹/모바일 트래픽 처리 용도(웹 계층), 데이터베이스용(데이터 계층)
    - 어떤 데이터베이스를 사용할 것인가?
        - 관계형 데이터베이스(RDBMS, Relational Database Management System)
        - 비관계형 데이터베이스(NoSQL)
            - key-value store, graph store, column store, document store
            - 비관계형 데이터베이스가 바람직한 경우
                - 아주 낮은 응답 지연시간(latency)이 요구됨
                - 다루는 데이터가 비정형(unstructured)이라 관계형 데이터가 아님
                - 데이터(JSON, YAML, XML 등)를 직렬화, 역직렬화 할 수 있기만 하면 됨
                - 아주 많은 양의 데이터를 저장할 필요가 있음
- 수직적 규모 확장 vs 수평적 규모 확장
    - 수직적 규모 확장(scale up, vertical scaling)
        - 서버에 고사양 자원(더 좋은 CPU, 더 많은 RAM 등)을 추가하는 행위
        - 서버로 유입되는 트래픽의 양이 적을 때는 수직적 확장이 좋은 선택
        - 단점
            - 수직적 규모 확장에는 한계가 있다. 한 대의 서버에 CPU나 메모리를 무한대로 증설할 방법이 없다.
            - 수직적 규모 확장법은 장애에 대한 자동복구(failover) 방안이나 다중화(redundancy) 방안을 제시하지 않는다. 서버에 장애가 발생하면 웹사이트/앱은 완전히 중단된다.
    - 수평적 규모 확장(scale out)
        - 더 많은 서버를 추가해 성능을 개선함
        - 대규모 애플리케이션을 지원하는 데에 더 적합
- 로드밸런서
    - 부하 분산 집합(load balancing set)에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할을 한다.
    - 사용자는 로드밸런서의 공개 IP 주소로 접속한다.
    - 웹 서버는 클라이언트의 접속을 직접 처리하지 않는다.
    - 보안을 위해 서버 간 통신에서는 사설 IP 주소가 이용된다.
    - 사설 IP 주소는 같은 네트워크에 속한 서버 사이의 통신에만 쓰일 수 있는 IP 주소로, 인터넷을 통해서는 접속할 수 없다. 로드밸런서는 웹 서버와 통신하기 위해 이 사설 주소를 이용함
    - 부하 분산 집합에 또 하나의 웹 서버를 추가하고 나면 장애를 자동복구하지 못하는 문제(no failover)는 해소되며, 웹 계층의 가용성은 향상된다.
        - 서버 1이 다운되면 모든 트래픽은 서버 2로 전송된다. 따라서 웹 사이트 전체가 다운되는 일이 방지된다. 부하를 나누기 위해 새로운 서버를 추가할 수도 있다.
        - 웹사이트로 유입되는 트래픽이 가파르게 증가하면 두 대의 서버로 트래픽을 감당할 수 없는 시점이 오는데, 로드밸런서가 있으므로 우아하게 대처할 수 있다. 웹 서버 계층에 더 많은 서버를 추가하기만 하면 된다. 그러면 로드밸런스가 자동적으로 트래픽을 분산하기 시작할 것이다.
- 데이터베이스의 다중화
    - 서버 사이에 주(master)-부(slave) 관계를 설정하고 데이터 원본은 주 서버에, 사본은 부 서버에 저장하는 방식
    - 쓰기 연산(write operation)은 마스터에서만 지원하고, 부 데이터베이스는 주 데이터베이스로부터 그 사본을 전달받으며, 읽기 연산만을 지원한다.(read operation)
    - 대부분의 애플리케이션은 읽기 연산의 비중이 쓰기 연산보다 높다. 따라서 통상 부 데이터베이스의 수가 주 데이터베이스 수보다 많다.
    - 데이터베이스 다중화의 장점
        - 더 나은 성능 : master-slave 다중화 모델에서 모든 데이터 변경 연산은 주 데이터베이스 서버로만 전달되는 반면 읽기 연산은 부 데이터베이스 서버들로 분산된다. 병렬로 처리될 수 있는 query의 수가 늘어나므로, 성능이 좋아진다.
        - 안전성(reliability) : 자연 재해 등의 이유로 데이터베이스 서버 가운데 일부가 파괴되어도 데이터는 보존될 것이다. 데이터를 지역적으로 떨어진 여러 장소에 다중화시켜 놓을 수 있기 때문이다.
        - 가용성(availablity) : 데이터를 여러 지역에 복제해 둠으로써, 하나의 데이터베이스 서버에 장애가 발생하더라도 다른 서버에 있는 데이터를 가져와 계속 서비스할 수 있게 된다.
    - 데이터베이스 서버 가운데 하나가 다운되면 무슨 일이 벌어질까?
        - 부 서버가 한 대 뿐인데 다운된 경우라면, 읽기 연산은 한시적으로 모두 주 데이터베이스로 전달될 것이다. 또한 즉시 새로운 부 데이터베이스 서버가 장애 서버를 대체할 것이다. 부 서버가 여러 대인 경우에 읽기 연산은 나머지 부 데이터베이스 서버들로 분산될 것이며, 새로운 부 데이터베이스 서버가 장애 서버를 대체할 것이다.
        - 주 데이터베이스 서버가 다운되면, 한 대의 부 데이터베이스만 있는 경우 해당 부 데이터베이스 서버가 새로운 주 서버가 될 것이며, 모든 데이터베이스 연산은 일시적으로 새로운 주 서버상에서 수행될 것이다. 그리고 새로운 부 서버가 추가될 것이다. 프로덕션 환경에서 벌어지는 일은 이보다 더 복잡한데, 부 서버에 보관한 데이터가 최신 상태가 아닐 수도 있기 때문이다. 없는 데이터는 복구 스크립트(recovery script)를 돌려서 추가해야 한다. 다중 마스터(multi-master)나 원형 다중화(circular replication) 방식을 도입하면 이런 상황에 대처하는 데 도움이 될 수도 있지만 해당 구성은 훨씬 복잡하며 그에 대한 논의는 이 책 범위를 벗어난다.
- 응답시간(latency)은 어떻게 개선할 수 있을까?
    - 캐시
        - 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고, 뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소다.
        - 웹페이지를 새로고침 할 때마다 표시할 데이터를 가져오기 위해 한 번 이상의 데이터베이스 호출이 발생한다. 애플리케이션의 성능은 데이터베이스를 얼마나 자주 호출하느냐에 크게 좌우되는데, 캐시는 그런 문제를 완화할 수 있다.
        - cahce tier(캐시 계층)
            - 성능 개선, 데이터베이스 부하 줄임, 캐시의 독립적 확장 가능
        - 읽기 주도형 캐시 전략(read-through caching strategy)
            1. 만일 데이터가 캐시에 있으면 캐시에서 데이터를 읽음
            2. 데이터가 캐시에 없으면 데이터베이스에서 해당 데이터를 읽어 캐시에 씀
            3. 웹 서버에 데이터를 반환
        - 이외에도 다양한 캐시 전략이 있는데, 캐시할 데이터 종류, 크기, 액세스 패턴에 맞는 캐시 전략을 선택하면 된다.
        - memcached API example
            
            ```java
            SECONDS = 1
            cache.set('myKey', 'hi there', 3600 * SECONDS)
            cache.get('myKey')
            ```
            
        - 캐시 사용 시 유의할 점
            - 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어난다면 고려할만함
            - 영속적으로 보관할 데이터를 캐시에 두는 것은 바람직하지 않다. 휘발성 메모리! 예를 들어, 캐시 서버가 재시작되면 캐시 내의 모든 데이터는 사라진다. 중요 데이터는 여전히 영속적인 저장소에 둬야한다.
            - 캐시에 보관된 데이터는 어떻게 만료되는가? 이에 대한 정책을 마련해 두는 것은 좋은 습관이다. 만료된 데이터는 캐시에서 삭제되어야 한다. 만료 정책이 없으면 데이터는 캐시에 계속 남게 된다. 만료 기한은 너무 짧으면 곤란한데 데이터베이스를 너무 자주 읽게 될 것이기 때문이다. 너무 길어도 곤란한데, 원본과 차이가 날 가능성이 높아지기 때문이다.
            - 일관성(consistency)는 어떻게 유지되는가? 일관성은 데이터 저장소의 원본과 캐시 내의 사본이 같은지 여부다. 저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우 이 일관성은 깨질 수 있다. 여러 지역에 걸쳐 시스템을 확장해 나가는 경우 캐시와 저장소 사이 일관성을 유지하는 것은 어려운 문제가 된다.
            - 장애에는 어떻게 대처할 것인가? 캐시 서버를 한 대만 두는 경우 해당 서버는 단일 장애 지점(Single Point of Failure, SPOF)이 되어버릴 가능성이 있다. 어떤 특정 지점에서의 장애가 전체 시스템의 동작을 중단시켜버릴 수 있는 경우, 그 해당 지점을 단일 장애 지점이라고 부른다. 결과적으로 SPOF를 피하려면 여러 지역에 걸쳐 캐시 서버를 분산시켜야 한다.
            - 캐시 메모리는 얼마나 크게 잡을 것인가? 캐시 메모리가 너무 작으면 액세스 패턴에 따라서는 데이터가 너무 자주 캐시에서 밀려나버려(eviction) 캐시의 성능이 떨어지게 된다. 이를 막을 한 가지 방법은 캐시 메모리를 과할당(overprovision)하는 것이다. 이렇게 하면 캐시에 보관될 데이터가 갑자기 늘어났을 때 생길 문제도 방지할 수 있게 된다.
            - 데이터 방출(eviction) 정책은 무엇인가? 캐시가 꽉 차버리면 추가로 캐시에 데이터를 넣어야 할 경우 기존 데이터를 내보내야 한다. 이것을 캐시 데이터 방출 정책이라 하는데, 그 가운데 가장 널리 쓰이는 것은 LRU(Least Recently Used - 마지막으로 사용된 시점이 가장 오래된 데이터를 내보내는 정책)이다. 다른 정책으로는 LFU(Least Frequently Used - 사용된 빈도가 가장 낮은 데이터를 내보내는 정책)나 FIFO(First In First Out - 가장 먼저 캐시에 들어온 데이터를 가장 먼저 내보내는 정책) 같은 것도 있으며, 경우에 맞게 적용 가능하다.
    - CDN(Content Delivery Network)
        - 정적 콘텐츠를 전송하는 데 쓰이는, 지리적으로 분산된 서버의 네트워크이다. 이미지, 비디오, CSS, JavaScript 파일 등을 캐시할 수 있다.
        - 동적 콘텐츠 캐싱은 상대적으로 새로운 개념으로, 이 책에서 다룰 수 있는 범위 밖이다. 간단히 요약하면, 요청 경로, 질의 문자열(query string), 쿠키(cookie), 요청 헤더(request header) 등의 정보에 기반해 HTML 페이지를 캐시하는 것이다.
        - CDN의 동작과정
            - 어떤 사용자가 웹 사이트를 방문하면, 그 사용자에게 가장 가까운 CDN 서버가 정적 콘텐츠를 전달하게 된다.
            - 직관적으로 당연하지만, 사용자가 CDN 서버로부터 멀면 멀수록 웹사이트는 천천히 로드될 것이다. 예를 들어, CDN 서버가 샌프란시스코에 있다면, LA에 있는 사용자는 유럽 사용자보다 빠른 웹 사이트를 보게 될 것이다.
            1. 사용자 A가 이미지 URL을 이용해 image.png에 접근한다. URL의 도메인은 CDN 서비스 사업자가 제공한 것이다. (Cloudfront, Akamai)
            2. CDN 서버의 캐시에 해당 이미지가 없는 경우, 원본 서버에 요청해 파일을 가져온다. 원본 서버는 웹 서버일 수도 있고 아마존 S3 같은 온라인 저장소일 수도 있다.
            3. 원본 서버가 파일을 CDN에 반환한다. 응답의 HTTP 헤더에는 해당 파일이 얼마나 오래 캐시될 수 있는지를 설명하는 TTL(Time-To-Live) 값이 들어있다.
            4. CDN 서버는 파일을 캐시하고 사용자에게 반환한다. 이미지는 TTL에 명시된 시간이 끝날 때까지 캐시된다.
            5. 사용자 B가 같은 이미지에 대한 요청을 CDN 서버에 전송한다.
            6. 만료되지 않은 이미지에 대한 요청은 캐시를 통해 처리된다.
        - CDN 사용 시 고려해야 할 사항
            - 비용 : 자주 사용되지 않는 컨텐츠를 캐싱하는 것은 이득이 크지 않으므로 빼기, CDN은 보통 제3 사업자에 의해 운영되어 데이터 전송 양에 따라 요금을 냄
            - 적절한 만료 시한 설정 : time-sensitive 콘텐츠의 경우 만료 시점을 잘 설정해야 한다. 너무 길면 콘텐츠의 신선도가 떨어지고, 너무 짧으면 원본 서버에 빈번히 접속해야 하니 좋지 않다.
            - CDN 장애에 대한 대처 방안 : CDN 자체가 죽었을 경우 웹사이트/애플리케이션이 어떻게 동작해야 하는지 고려해야 한다. 가령 일시적으로 CDN이 응답하지 않을 경우, 해당 문제를 감지해 원본 서버로부터 직접 콘텐츠를 가져오도록 클라이언트를 구성하는 것이 필요할 수도 있다.
            - 콘텐츠 무효화(invalidation) 방법 : 아직 만료되지 않은 콘텐츠라 하더라도 아래 방법 가운데 하나를 쓰면 CDN으로 제거할 수도 있다.
                - CDN 서비스 사업자가 제공하는 API를 이용해 콘텐츠 무효화
                - 콘텐츠의 다른 버전을 서비스하도록 오브젝트 버저닝(object versioning) 이용. 콘텐츠의 새로운 버전을 지정하기 위해서는 URL의 마지막에 버전 번호를 인자로 주면 된다. 예를 들어, image.png?v=2 같은 식이다.
- stateless 웹 계층
- 데이터 센터
- 메시지 큐
- 로그, 메트릭 그리고 자동화
- 데이터베이스의 규모 확장
- 백만 사용자, 그리고 그 이상